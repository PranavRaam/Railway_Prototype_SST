^C
^C
^C
^C
^C
import geopandas as gpd
import folium
from folium.plugins import MousePosition, Search, Fullscreen, MiniMap, Draw
import branca.colormap as cm
import pandas as pd
import numpy as np
import requests
import io
import os
import zipfile
import tempfile
from folium import IFrame, Figure
from branca.element import MacroElement
from jinja2 import Template

class LegendControl(MacroElement):
    def __init__(self, title, color_dict, position='bottomright'):
        super(LegendControl, self).__init__()
        self._name = 'LegendControl'
        self.title = title
        self.color_dict = color_dict
        self.position = position
        
        self.template = Template("""
            {% macro script(this, kwargs) %}
            var legend = L.control({position: "{{this.position}}"});
            legend.onAdd = function (map) {
                var div = L.DomUtil.create("div", "legend");
                div.innerHTML = `
                    <div style="background-color: white; padding: 10px; border-radius: 5px; border: 2px solid gray;">
                        <div style="text-align: center; margin-bottom: 5px; font-weight: bold;">{{this.title}}</div>
                        <div style="display: flex; flex-direction: column; gap: 5px;">
                            {% for name, color in this.color_dict.items() %}
                                <div style="display: flex; align-items: center;">
                                    <span style="background: {{color}}; width: 20px; height: 15px; display: inline-block;"></span>
                                    <span style="margin-left: 5px; font-size: 12px;">{{name}}</span>
                                </div>
                            {% endfor %}
                        </div>
                    </div>
                `;
                return div;
            };
            legend.addTo({{this._parent.get_name()}});
            {% endmacro %}
        """)

def download_and_unzip(url, extract_to=None, cache=True):
    if extract_to is None:
        extract_to = tempfile.mkdtemp()
        
    cache_dir = os.path.join(tempfile.gettempdir(), 'county_map_cache')
    os.makedirs(cache_dir, exist_ok=True)
    
    cache_key = os.path.basename(url)
    cache_path = os.path.join(cache_dir, cache_key)
    
    if cache and os.path.exists(cache_path):
        print(f"Using cached data for {url}")
        return cache_path
    
    print(f"Downloading data from {url}...")
    response = requests.get(url)
    if response.status_code != 200:
        raise Exception(f"Failed to download from {url}. Status code: {response.status_code}")
        
    output_dir = cache_path if cache else extract_to
    os.makedirs(output_dir, exist_ok=True)
    
    z = zipfile.ZipFile(io.BytesIO(response.content))
    z.extractall(output_dir)
    print(f"Data extracted to {output_dir}")
    return output_dir

def get_county_data(use_alternative_loading=False):
    """Get county data from Census TIGER/Line shapefiles"""
    url = "https://www2.census.gov/geo/tiger/TIGER2023/COUNTY/tl_2023_us_county.zip"
    data_dir = download_and_unzip(url)
    
    county_file = os.path.join(data_dir, "tl_2023_us_county.shp")
    
    try:
        if use_alternative_loading:
            # Alternative loading method without relying on fiona.path
            import json
            import shapely.geometry
            from shapefile import Reader
            
            # Read the shapefile using pyshp instead of fiona
            reader = Reader(county_file)
            county_records = []
            
            # Extract records and shapes
            for sr in reader.shapeRecords():
                attrs = sr.record.as_dict()
                
                # Create a shapely geometry from the shape points
                if sr.shape.shapeType == 5:  # Polygon
                    pts = sr.shape.points
                    if len(pts) < 3:  # Need at least 3 points for a polygon
                        continue
                    geom = shapely.geometry.Polygon(pts)
                else:
                    # Skip non-polygon shapes
                    continue
                
                # Add essential attributes and geometry
                record = {
                    'STATEFP': attrs.get('STATEFP', ''),
                    'COUNTYFP': attrs.get('COUNTYFP', ''),
                    'NAME': attrs.get('NAME', ''),
                    'geometry': geom
                }
                county_records.append(record)
            
            # Create a GeoDataFrame from the records
            import pandas as pd
            import geopandas as gpd
            county_data = gpd.GeoDataFrame(county_records, crs="EPSG:4326")
        else:
            # Standard loading with geopandas/fiona
            county_data = gpd.read_file(county_file)
    except Exception as e:
        print(f"Error loading county data: {str(e)}")
        print("Falling back to alternative loading method")
        # If standard method fails, try alternative anyway
        import json
        import shapely.geometry
        from shapefile import Reader
        
        # Read the shapefile using pyshp instead of fiona
        reader = Reader(county_file)
        county_records = []
        
        # Extract records and shapes
        for sr in reader.shapeRecords():
            attrs = sr.record.as_dict()
            
            # Create a shapely geometry from the shape points
            if sr.shape.shapeType == 5:  # Polygon
                pts = sr.shape.points
                if len(pts) < 3:  # Need at least 3 points for a polygon
                    continue
                geom = shapely.geometry.Polygon(pts)
            else:
                # Skip non-polygon shapes
                continue
            
            # Add essential attributes and geometry
            record = {
                'STATEFP': attrs.get('STATEFP', ''),
                'COUNTYFP': attrs.get('COUNTYFP', ''),
                'NAME': attrs.get('NAME', ''),
                'geometry': geom
            }
            county_records.append(record)
        
        # Create a GeoDataFrame from the records
        import pandas as pd
        import geopandas as gpd
        county_data = gpd.GeoDataFrame(county_records, crs="EPSG:4326")
    
    # Filter US states only
    county_data = county_data[county_data['STATEFP'].isin([
        '01', '02', '04', '05', '06', '08', '09', '10', '11', '12', '13', '15', '16', '17', '18', '19',
        '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35',
        '36', '37', '38', '39', '40', '41', '42', '44', '45', '46', '47', '48', '49', '50', '51', '53', '54', '55', '56'
    ])]
    
    # Simplify geometries
    county_data['geometry'] = county_data.geometry.simplify(0.01)
    
    return county_data

def get_states_data(use_alternative_loading=False):
    """Get state data from Census TIGER/Line shapefiles"""
    url = "https://www2.census.gov/geo/tiger/TIGER2023/STATE/tl_2023_us_state.zip"
    data_dir = download_and_unzip(url)
    
    states_file = os.path.join(data_dir, "tl_2023_us_state.shp")
    
    try:
        if use_alternative_loading:
            # Alternative loading method without relying on fiona.path
            import json
            import shapely.geometry
            from shapefile import Reader
            
            # Read the shapefile using pyshp instead of fiona
            reader = Reader(states_file)
            state_records = []
            
            # Extract records and shapes
            for sr in reader.shapeRecords():
                attrs = sr.record.as_dict()
                
                # Create a shapely geometry from the shape points
                if sr.shape.shapeType == 5:  # Polygon
                    pts = sr.shape.points
                    if len(pts) < 3:  # Need at least 3 points for a polygon
                        continue
                    geom = shapely.geometry.Polygon(pts)
                else:
                    # Skip non-polygon shapes
                    continue
                
                # Add essential attributes and geometry
                record = {
                    'STATEFP': attrs.get('STATEFP', ''),
                    'STUSPS': attrs.get('STUSPS', ''),
                    'NAME': attrs.get('NAME', ''),
                    'geometry': geom
                }
                state_records.append(record)
            
            # Create a GeoDataFrame from the records
            import pandas as pd
            import geopandas as gpd
            states_data = gpd.GeoDataFrame(state_records, crs="EPSG:4326")
        else:
            # Standard loading with geopandas/fiona
            states_data = gpd.read_file(states_file)
    except Exception as e:
        print(f"Error loading states data: {str(e)}")
        print("Falling back to alternative loading method")
        # If standard method fails, try alternative anyway
        import json
        import shapely.geometry
        from shapefile import Reader
        
        # Read the shapefile using pyshp instead of fiona
        reader = Reader(states_file)
        state_records = []
        
        # Extract records and shapes
        for sr in reader.shapeRecords():
            attrs = sr.record.as_dict()
            
            # Create a shapely geometry from the shape points
            if sr.shape.shapeType == 5:  # Polygon
                pts = sr.shape.points
                if len(pts) < 3:  # Need at least 3 points for a polygon
                    continue
                geom = shapely.geometry.Polygon(pts)
            else:
                # Skip non-polygon shapes
                continue
            
            # Add essential attributes and geometry
            record = {
                'STATEFP': attrs.get('STATEFP', ''),
                'STUSPS': attrs.get('STUSPS', ''),
                'NAME': attrs.get('NAME', ''),
                'geometry': geom
            }
            state_records.append(record)
        
        # Create a GeoDataFrame from the records
        import pandas as pd
        import geopandas as gpd
        states_data = gpd.GeoDataFrame(state_records, crs="EPSG:4326")
    
    # Filter out territories
    states_data = states_data[~states_data['STUSPS'].isin(['AS', 'GU', 'MP', 'PR', 'VI'])]
    states_data['geometry'] = states_data.geometry.simplify(0.01)
    
    return states_data

def get_msa_data(use_alternative_loading=False):
    """Get Metropolitan Statistical Area data from Census TIGER/Line shapefiles"""
    try:
        url = "https://www2.census.gov/geo/tiger/TIGER2023/CBSA/tl_2023_us_cbsa.zip"
        data_dir = download_and_unzip(url)
        
        msa_file = os.path.join(data_dir, "tl_2023_us_cbsa.shp")
        
        if use_alternative_loading:
            print("Using alternative loading method for MSA data")
            # Alternative loading method without relying on fiona.path
            import json
            import shapely.geometry
            from shapefile import Reader
            
            # Read the shapefile using pyshp instead of fiona
            reader = Reader(msa_file)
            msa_records = []
            
            # Extract records and shapes
            for sr in reader.shapeRecords():
                attrs = sr.record.as_dict()
                
                # Create a shapely geometry from the shape points
                if sr.shape.shapeType == 5:  # Polygon
                    pts = sr.shape.points
                    if len(pts) < 3:  # Need at least 3 points for a polygon
                        continue
                    geom = shapely.geometry.Polygon(pts)
                else:
                    # Skip non-polygon shapes
                    continue
                
                # Add essential attributes and geometry
                record = {
                    'CBSAFP': attrs.get('CBSAFP', ''),
                    'NAME': attrs.get('NAME', ''),
                    'LSAD': attrs.get('LSAD', ''),
                    'geometry': geom
                }
                msa_records.append(record)
            
            # Create a GeoDataFrame from the records
            import pandas as pd
            import geopandas as gpd
            msa_data = gpd.GeoDataFrame(msa_records, crs="EPSG:4326")
        else:
            # Standard loading with geopandas/fiona
            msa_data = gpd.read_file(msa_file)
        
        # Filter for Metropolitan Statistical Areas (both M1 and M2)
        # M1 = Metropolitan Statistical Area
        # M2 = Metropolitan Division
        if 'LSAD' in msa_data.columns:
            filtered_msa_data = msa_data[msa_data['LSAD'].isin(['M1', 'M2'])]
            if len(filtered_msa_data) > 0:
                msa_data = filtered_msa_data
            else:
                print("Warning: No MSA data found after filtering!")
                print(f"Available LSAD values: {msa_data['LSAD'].unique()}")
        else:
            print("Warning: LSAD column not found in MSA data")
        
        # Ensure we have the required columns
        required_columns = ['CBSAFP', 'NAME', 'geometry']
        missing_columns = [col for col in required_columns if col not in msa_data.columns]
        if missing_columns:
            raise Exception(f"Missing required columns in MSA data: {missing_columns}")
        
        # Clean and process the data
        msa_data['geometry'] = msa_data.geometry.simplify(0.01)
        msa_data = msa_data.copy()  # Make a copy to avoid SettingWithCopyWarning
        
        # Add placeholder for state count
        msa_data['STATE_COUNT'] = 0
        
        print(f"Loaded {len(msa_data)} Metropolitan Statistical Areas")
        return msa_data
        
    except Exception as e:
        print(f"Error loading MSA data: {str(e)}")
        print("Trying alternative loading method...")
        
        try:
            # Fall back to alternative method even if not explicitly requested
            url = "https://www2.census.gov/geo/tiger/TIGER2023/CBSA/tl_2023_us_cbsa.zip"
            data_dir = download_and_unzip(url)
            
            msa_file = os.path.join(data_dir, "tl_2023_us_cbsa.shp")
            
            # Alternative loading method without relying on fiona.path
            import json
            import shapely.geometry
            from shapefile import Reader
            
            # Read the shapefile using pyshp instead of fiona
            reader = Reader(msa_file)
            msa_records = []
            
            # Extract records and shapes
            for sr in reader.shapeRecords():
                attrs = sr.record.as_dict()
                
                # Create a shapely geometry from the shape points
                if sr.shape.shapeType == 5:  # Polygon
                    pts = sr.shape.points
                    if len(pts) < 3:  # Need at least 3 points for a polygon
                        continue
                    geom = shapely.geometry.Polygon(pts)
                else:
                    # Skip non-polygon shapes
                    continue
                
                # Add essential attributes and geometry
                record = {
                    'CBSAFP': attrs.get('CBSAFP', ''),
                    'NAME': attrs.get('NAME', ''),
                    'LSAD': attrs.get('LSAD', ''),
                    'geometry': geom
                }
                msa_records.append(record)
            
            # Create a GeoDataFrame from the records
            import pandas as pd
            import geopandas as gpd
            msa_data = gpd.GeoDataFrame(msa_records, crs="EPSG:4326")
            
            # Filter for Metropolitan Statistical Areas if LSAD column exists
            if 'LSAD' in msa_data.columns:
                filtered_msa_data = msa_data[msa_data['LSAD'].isin(['M1', 'M2'])]
                if len(filtered_msa_data) > 0:
                    msa_data = filtered_msa_data
            
            # Add placeholder for state count
            msa_data['STATE_COUNT'] = 0
            
            print(f"Loaded {len(msa_data)} Metropolitan Statistical Areas using alternative method")
            return msa_data
            
        except Exception as fallback_error:
            print(f"Alternative loading method also failed: {str(fallback_error)}")
            return None

def get_county_msa_relationships():
    try:
        url = "https://www2.census.gov/programs-surveys/metro-micro/geographies/reference-files/2020/delineation-files/list1_2020.xls"
        print(f"Downloading MSA-County relationships from {url}...")
        response = requests.get(url)
        if response.status_code != 200:
            url = "https://www2.census.gov/programs-surveys/metro-micro/geographies/reference-files/2020/delineation-files/list1.xls"
            print(f"First URL failed. Trying alternative: {url}")
            response = requests.get(url)
            if response.status_code != 200:
                raise Exception(f"Failed to download MSA-County relationships. Status code: {response.status_code}")
        
        df = pd.read_excel(io.BytesIO(response.content), header=2)
        
        # Ensure column names exist before renaming
        if all(col in df.columns for col in ['FIPS State Code', 'FIPS County Code', 'CBSA Code', 'CBSA Title', 'Metropolitan/Micropolitan Statistical Area']):
            df = df.rename(columns={
                'FIPS State Code': 'STATEFP',
                'FIPS County Code': 'COUNTYFP',
                'CBSA Code': 'CBSAFP',
                'CBSA Title': 'CBSA_NAME',
                'Metropolitan/Micropolitan Statistical Area': 'LSAD'
            })
        else:
            # Try alternate column names that might be present
            possible_columns = {
                'State Code': 'STATEFP',
                'County Code': 'COUNTYFP', 
                'CBSA Code': 'CBSAFP',
                'CBSA Title': 'CBSA_NAME',
                'Metropolitan Division Title': 'CBSA_NAME',
                'Metropolitan/Micropolitan Statistical Area': 'LSAD',
                'CBSA Type': 'LSAD'
            }
            
            rename_dict = {}
            for old_col, new_col in possible_columns.items():
                if old_col in df.columns:
                    rename_dict[old_col] = new_col
            
            if rename_dict:
                df = df.rename(columns=rename_dict)
            else:
                print("Warning: Expected columns not found in MSA-County relationship file")
                print(f"Available columns: {df.columns.tolist()}")
                raise Exception("Could not map MSA-County relationship file columns")
        
    except Exception as e:
        print(f"Warning: Couldn't download or process the MSA-County relationship file: {e}")
        print("Attempting to create relationships from the CBSA and County shapefiles directly...")
        
        county_data = get_county_data()
        msa_data = get_msa_data()
        
        if county_data.crs != msa_data.crs:
            msa_data = msa_data.to_crs(county_data.crs)
        
        counties_list = []
        for _, county in county_data.iterrows():
            county_point = county.geometry.centroid
            
            for _, msa in msa_data.iterrows():
                if msa.geometry.contains(county_point):
                    counties_list.append({
                        'STATEFP': county['STATEFP'],
                        'COUNTYFP': county['COUNTYFP'],
                        'CBSAFP': msa['CBSAFP'],
                        'CBSA_NAME': msa['NAME'],
                        'LSAD': 'Metropolitan Statistical Area',
                    })
                    break
                    
        df = pd.DataFrame(counties_list)
    
    # Create county_to_msa dictionary
    county_to_msa = {}
    if set(['STATEFP', 'COUNTYFP', 'CBSAFP']).issubset(df.columns):
        df['STATEFP'] = df['STATEFP'].astype(str).str.zfill(2)
        df['COUNTYFP'] = df['COUNTYFP'].astype(str).str.zfill(3)
        
        # Filter to metropolitan areas if LSAD column exists
        if 'LSAD' in df.columns:
            df = df[df['LSAD'].str.contains('Metro', case=False, na=False)]
        
        for _, row in df.iterrows():
            county_id = row['STATEFP'] + row['COUNTYFP']
            county_to_msa[county_id] = {
                'CBSAFP': row['CBSAFP'],
                'CBSA_NAME': row.get('CBSA_NAME', row.get('NAME', ''))  # Try alternative column name
            }
    
    if not county_to_msa:
        print("Warning: Could not create MSA-County relationships. MSA information may be incomplete.")
    
    return county_to_msa, df

def define_regions():
    # Create a color palette matching the image
    regions = {
        "Pacific Northwest Division": {
            "states": ["WA", "OR", "AK", "HI"],
            "color": "#FF5B76"  # Pink-Red
        },
        "Intermountain Division": {
            "states": ["MT", "ID", "WY", "NV", "UT", "CO"],
            "color": "#FF9A8B"  # Light Salmon
        },
        "Southwest Division": {
            "states": ["AZ", "NM"],  # Will also include specific TX counties
            "color": "#FF6C5C"  # Coral-Red
        },
        "LA CA Division": {
            "states": [],  # Will be populated with specific CA counties
            "color": "#CC0000"  # Deep Red
        },
        "Bay Area Central CA Division": {
            "states": [],  # Will be populated with specific CA counties
            "color": "#FFBDB4"  # Pale Pink
        },
        "Great Plains Division": {
            "states": ["ND", "SD", "NE", "KS", "MN", "IA"],  # Will also include specific MO counties
            "color": "#FFF7AA"  # Light Yellow
        },
        "Illinois Wisconsin Division": {
            "states": ["WI", "IL"],  # Will exclude specific IL counties
            "color": "#FFBB8B"  # Light Orange
        },
        "Central Division 3": {
            "states": ["OK", "MO"],  # Will include specific OK counties and exclude specific MO counties
            "color": "#FFFF00"  # Bright Yellow
        },
        "The South Division": {
            "states": ["AR", "LA", "MS", "AL"],
            "color": "#bfab97"  # Very Pale Yellow
        },
        "Central & East Texas Division": {
            "states": [],  # Will be populated with specific TX counties
            "color": "#F0F0DC"  # Light Beige
        },
        "NEMA Divisional GRP Division 1": {
            "states": ["ME", "NH", "VT", "MA", "CT", "RI"],
            "color": "#702080"  # Deep Purple
        },
        "NEMA Divisional GRP Division 2": {
            "states": ["NJ"],  # Will also include specific NY counties
            "color": "#4B0082"  # Indigo
        },
        "NEMA Divisional GRP Division 3": {
            "states": ["PA", "DE"],  # Will also include specific NY counties
            "color": "#CCCCFF"  # Very Light Purple
        },
        "NEMA Divisional GRP Division 4": {
            "states": ["VA", "MD", "DC"],
            "color": "#AA80C0"  # Medium Purple
        },
        "NEMA Divisional GRP Division 5": {
            "states": ["NC", "SC"],
            "color": "#D8BFD8"  # Thistle (Light Purple)
        },
        "East Central Division 1": {
            "states": ["NY", "OH", "WV"],  # Will exclude specific NY counties and include specific PA counties
            "color": "#D6F6D5"  # Very Light Blue
        },
        "East Central Division 2": {
            "states": ["MI", "IN"],
            "color": "#90EE90"  # Light Green
        },
        "East Central Division 3": {
            "states": ["KY", "TN"],  # Also includes "West OS" (possibly West Ohio)
            "color": "#2F8F71"  # Teal Green
        },
        "East Central Division 4": {
            "states": ["GA"],  # Also includes parts of FL not explicitly mentioned
            "color": "#218C74"  # Forest Green
        },
        "East Central Division 5": {
            "states": [],  # Will be populated with specific FL counties
            "color": "#ABEBC6"  # Light Green
        }
    }
    
    # Define special county assignments
    # Southwest Division - specific TX counties
    southwest_tx_counties = [
        "Bailey", "Sherman", "Hansford", "Ochiltree", "Lipscomb", "Hartley", "Moore", 
        "Hutchinson", "Roberts", "Hemphill", "Oldham", "Potter", "Carson", "Gray", 
        "Wheeler", "Deaf Smith", "Randall", "Armstrong", "Donley", "Collingsworth", 
        "Parmer", "Castro", "Swisher", "Briscoe", "Hall", "Childress", "Hardeman", 
        "Foard", "Knox", "Baylor", "Cochran", "Hockley", "Crosby", "Dickens", "King", 
        "Yoakum", "Terry", "Lynn", "Garza", "Kent", "Gaines", "Dawson", "Borden", 
        "Scurry", "Andrews", "Martin", "Howard", "Mitchell", "Nolan", "El Paso", 
        "Hudspeth", "Culberson", "Reeves", "Pecos", "Jeff Davis", "Presidio", 
        "Brewster", "Terrell", "Val Verde", "Loving", "Winkler", "Ector", "Midland", 
        "Glasscock", "Sterling", "Coke", "Reagan", "Irion", "Tom Green", "Concho", 
        "McCulloch", "Crockett", "Schleicher", "Menard", "Mason", "Sutton", "Kimble", 
        "Edwards", "Real", "Kinney", "Uvalde", "Maverick", "Zavala", "Dimmit", "Frio", 
        "La Salle", "McMullen", "Live Oak", "Bee", "Goliad", "Victoria", "Webb", 
        "Duval", "Jim Wells", "Kleberg", "Zapata", "Jim Hogg", "Kenedy", "Starr", 
        "Hidalgo", "Willacy", "Cameron", "Lamb", "Hale", "Floyd", "Motley",  "Cottle", 
        "Lubbock", "Ward", "Crane", "Upton", "Dallam", "Brooks"
    ]
    
    # Great Plains Division - specific MO counties
    great_plains_mo_counties = [
        "Platte", "Clinton", "Caldwell", "Clay", "Ray", "Jackson", "Lafayette", "Cass", "Bates"
    ]
    
    # Illinois Wisconsin Division - specific IL counties to exclude
    il_wi_exclude_counties = [
        "Jersey", "Macoupin", "Madison", "Bond", "Clinton", "St. Clair", "Monroe"
    ]
    
    # Central Division 3 - specific OK counties and DFW TX counties
    # Fixed the issue - these were incorrectly labeled as OK counties when they're TX counties
    central_div3_tx_counties = [
        "Montague", "Cooke", "Grayson", "Fannin", "Denton", "Collin", "Hunt", 
        "Rockwall", "Parker", "Tarrant", "Dallas", "Kaufman", "Hood", "Johnson", "Ellis"
    ]
    
    # NEMA Divisional GRP Division 2 - specific NY counties
    nema_div2_ny_counties = [
        "Pike", "Putnam", "Rockland", "Westchester", "Bronx", "Queens", "Kings", 
        "Richmond", "Suffolk", "Nassau", "New York"
    ]
    
    # NEMA Divisional GRP Division 3 - specific NY counties
    nema_div3_ny_counties = ["Sullivan", "Ulster", "Dutchess", "Orange"]
    
    # East Central Division 1 - specific PA counties (fixed naming from OH/PA to PA only)
    east_central_div1_pa_counties = [
        "Erie", "Crawford", "Lawrence", "Butler", "Armstrong", "Beaver", "Allegheny", 
        "McKean", "Westmoreland", "Washington", "Fayette", "Greene"
    ]
    
    # East Central Division 5 - specific FL counties
    east_central_div5_fl_counties = [
        "Hernando", "Pasco", "Pinellas", "Hillsborough", "Manatee", "Sarasota", 
        "Charlotte", "Lee", "Collier", "Monroe", "Miami-Dade", "Broward", "Palm Beach", 
        "Martin", "St. Lucie", "Okeechobee", "Highlands", "Glades", "Hardee", "DeSoto", 
        "Sumter", "Lake", "Seminole", "Orange", "Osceola", "Brevard", "Indian River", "Polk",
        "Hendry"
    ]
    
    # California regions - more precisely defined with full county names
    ca_regions = {
        "LA CA Division": ["Los Angeles", "Orange", "Riverside", "San Bernardino", "San Diego", 
                           "Ventura", "Imperial", "Santa Barbara", "San Luis Obispo"],
        "Bay Area Central CA Division": ["Alameda", "Contra Costa", "Marin", "Napa", "San Francisco", 
                                        "San Mateo", "Santa Clara", "Solano", "Sonoma", "Sacramento", 
                                        "San Joaquin", "Stanislaus", "Merced", "Madera", "Fresno", 
                                        "Kings", "Tulare", "Kern", "Monterey", "San Benito", "Santa Cruz"]
    }
    
    # Create dictionaries of special county assignments with corrected labels
    special_county_regions = {
        "Southwest Division": {"TX": southwest_tx_counties},
        "Great Plains Division": {"MO": great_plains_mo_counties},
        "Central Division 3": {"TX": central_div3_tx_counties}, 
        "NEMA Divisional GRP Division 2": {"NY": nema_div2_ny_counties},  
        "NEMA Divisional GRP Division 3": {"NY": nema_div3_ny_counties},
        "East Central Division 1": {"PA": east_central_div1_pa_counties},
        "East Central Division 5": {"FL": east_central_div5_fl_counties}
    }
    
    # Counties to exclude from their default state assignment
    exclude_counties = {
        "IL": il_wi_exclude_counties,
        "NY": nema_div2_ny_counties + nema_div3_ny_counties  
    }
    
    return regions, ca_regions, special_county_regions, exclude_counties

def assign_counties_to_regions_and_msas(county_data, regions, ca_regions, special_county_regions, exclude_counties, county_to_msa):
    # Create a mapping from state code to region
    state_to_region = {}
    for region, data in regions.items():
        for state in data["states"]:
            state_to_region[state] = region
    
    # Get state data for mapping state codes to abbreviations
    states_data = get_states_data()
    state_mapping = dict(zip(states_data['STATEFP'], states_data['STUSPS']))
    
    # Add state abbreviations to county data
    county_data['STUSPS'] = county_data['STATEFP'].map(state_mapping)
    
    # Define function to assign regions
    def get_region(row):
        state = row['STUSPS']
        county_name = row['NAME']
        
        # First check if county is in any special county assignments
        for region, state_counties_dict in special_county_regions.items():
            for county_state, counties in state_counties_dict.items():
                if state == county_state and county_name in counties:
                    return region
        
        # Check if county should be excluded from default state assignment
        if state in exclude_counties and county_name in exclude_counties[state]:
            # For IL counties in the exclude list, assign to Central Division 3
            if state == "IL":
                return "Central Division 3"
            return "Unassigned"
        
        # Handle California counties
        if state == 'CA':
            for region, counties in ca_regions.items():
                if any(county_name == county for county in counties):
                    return region
            # Default for CA counties not explicitly assigned
            return "Bay Area Central CA Division"
        
        # Handle Texas counties not in Southwest Division or Central Division 3
        if state == 'TX':
            sw_counties = special_county_regions.get("Southwest Division", {}).get("TX", [])
            central_counties = special_county_regions.get("Central Division 3", {}).get("TX", [])
            
            if county_name in sw_counties:
                return "Southwest Division"
            elif county_name in central_counties:
                return "Central Division 3"
            else:
                return "Central & East Texas Division"
        
        # Handle Florida counties explicitly
        if state == 'FL':
            ec5_counties = special_county_regions.get("East Central Division 5", {}).get("FL", [])
            if county_name in ec5_counties:
                return "East Central Division 5"
            else:
                return "East Central Division 4"
        
        # Handle Delaware (entire state goes to NEMA Divisional GRP Division 3)
        if state == 'DE':
            return "NEMA Divisional GRP Division 3"
        
        # Handle other states based on default mappings
        return state_to_region.get(state, "Unassigned")
    
    # Apply the region assignment function
    county_data['Region'] = county_data.apply(get_region, axis=1)
    
    # Define function to get MSA info
    def get_msa_info(row):
        county_id = row['STATEFP'] + row['COUNTYFP']
        msa_info = county_to_msa.get(county_id, {})
        cbsafp = msa_info.get('CBSAFP', '')
        cbsa_name = msa_info.get('CBSA_NAME', '')
        return cbsafp, cbsa_name
    
    # Add MSA information to counties
    county_data['CBSAFP'], county_data['CBSA_NAME'] = zip(*county_data.apply(get_msa_info, axis=1))
    county_data['InMSA'] = county_data['CBSAFP'] != ''
    
    return county_data

def create_enhanced_interactive_map(county_data, msa_data, regions, center=[37.0902, -95.7129], zoom=4):
    """Create an enhanced interactive map with additional controls and visualizations"""
    
    # Create a base map
    m = folium.Map(
        location=center,
        zoom_start=zoom,
        tiles=None,  # We'll add our own tile layers
        control_scale=True,
    )
    
    # Add base map layers
    folium.TileLayer('cartodbpositron', name='Light Map', control=False).add_to(m)
    folium.TileLayer('cartodbdark_matter', name='Dark Map', control=False).add_to(m)
    folium.TileLayer('OpenStreetMap', name='Street Map', control=False).add_to(m)
    
    # Add counties colored by region
    style_function = lambda x: {
        'fillColor': x['properties']['color'],
        'color': 'gray',
            'weight': 0.5,
            'fillOpacity': 0.7
        }
        
    highlight_function = lambda x: {
        'fillColor': x['properties']['color'],
        'color': 'black',
        'weight': 1,
        'fillOpacity': 0.9
    }
    
    tooltip = folium.features.GeoJsonTooltip(
        fields=['NAME', 'REGION', 'MSA'],
        aliases=['County', 'Region', 'MSA'],
            localize=True,
            sticky=False,
            labels=True,
            style="""
            background-color: #F0EFEF;
                border: 2px solid black;
                border-radius: 3px;
            box-shadow: 3px;
        """,
        max_width=800,
    )
    
    # Convert to GeoJSON
    county_geojson = county_data.to_crs(epsg='4326').__geo_interface__
    
    # Add the GeoJSON layer with interactive tooltips
    counties_layer = folium.GeoJson(
        county_geojson,
            name='All Counties by Region',
        style_function=style_function,
        highlight_function=highlight_function,
        tooltip=tooltip,
    )
    counties_layer.add_to(m)
    
    # Add MSA boundaries if available
    if msa_data is not None and len(msa_data) > 0:
        msa_geojson = msa_data.to_crs(epsg='4326').__geo_interface__
        msa_layer = folium.GeoJson(
            msa_geojson,
            name='Metropolitan Statistical Areas',
            style_function=lambda x: {
                'fillColor': 'transparent',
                'color': '#3388ff',
                'weight': 2,
                'dashArray': '5, 5',
                'fillOpacity': 0.0
            },
            tooltip=folium.features.GeoJsonTooltip(
                fields=['NAME'],
                aliases=['MSA'],
                localize=True,
                sticky=False,
                labels=True,
            )
        )
        msa_layer.add_to(m)
    
    # Add state boundaries
    state_boundaries = folium.GeoJson(
        'https://raw.githubusercontent.com/PublicaMundi/MappingAPI/master/data/geojson/us-states.json',
        name='State Boundaries',
                style_function=lambda x: {
            'fillColor': 'transparent',
            'color': 'black',
                    'weight': 1,
            'fillOpacity': 0.0
        }
    )
    state_boundaries.add_to(m)
    
    # Add layer control
    folium.LayerControl(
        position='topright',
        collapsed=False,
        autoZIndex=True
    ).add_to(m)
    
    # Add scale bar
    folium.plugins.MeasureControl(
        position='bottomleft',
        primary_length_unit='kilometers',
        secondary_length_unit='miles',
        primary_area_unit='sqmeters',
        secondary_area_unit='acres'
    ).add_to(m)
    
    # Add fullscreen control
    Fullscreen(
        position='topleft',
        title='Fullscreen',
        title_cancel='Exit fullscreen',
        force_separate_button=True
    ).add_to(m)
    
    # Add search functionality
    Search(
        layer=counties_layer,
        geom_type='Point',
            placeholder='Search for a county',
            collapsed=True,
            search_label='NAME',
            search_zoom=10,
            position='topleft'
    ).add_to(m)
    
    # Add mouse position
    MousePosition(
        position='bottomright',
        separator=' | ',
        prefix='Coordinates:',
        num_digits=4,
        empty_string='',
        lng_first=False,
        control_position='bottomright'
    ).add_to(m)
    
    # Add a minimap
    minimap = MiniMap(
        position='bottomright',
        toggle_display=True,
        tile_layer=folium.TileLayer('cartodbpositron')
    )
    m.add_child(minimap)
    
    # Add draw control
    draw = Draw(
        position='topleft',
        draw_options={
            'polyline': True,
            'polygon': True,
            'rectangle': True,
            'circle': True,
            'marker': True,
            'circlemarker': False
        },
        edit_options={
            'featureGroup': None,
            'edit': True,
            'remove': True
        }
    )
    m.add_child(draw)
    
    # Add a title
    title_html = '''
        <div style="position: absolute; 
                    top: 10px; left: 50%;
                    transform: translateX(-50%);
                    z-index: 9999; width: 50%;
                    text-align: center;">
            <div style="background-color: white; 
                        padding: 10px; 
                        border-radius: 5px;
                        box-shadow: 3px 3px 10px rgba(0,0,0,0.2);">
                <h3 style="margin: 0; font-family: Arial, sans-serif;">US 20-Region Classification with MSA Boundaries</h3>
            </div>
        </div>
    '''
    m.get_root().html.add_child(folium.Element(title_html))
    
    # Add a legend for regions
    legend_colors = {region: data['color'] for region, data in regions.items()}
    legend = LegendControl(title='Region', color_dict=legend_colors, position='bottomleft')
    m.add_child(legend)
    
    # Add custom JavaScript for iframe communication
    iframe_communication_js = """
    <script>
    // Map interaction script for parent window communication
    window.addEventListener('load', function() {
        console.log('Map iframe loaded, initializing interaction handlers');
        
        // Reference to the current map and its layers
        let leafletMap = null;
        let baseMaps = {};
        let overlayMaps = {};
        
        // Try to find the Leaflet map instance in global scope
        for (let key in window) {
            if (key.startsWith('map_') && window[key] && typeof window[key].addLayer === 'function') {
                leafletMap = window[key];
                console.log('Found Leaflet map:', key);
                break;
            }
        }
        
        // Find layer controls
        for (let key in window) {
            if (key.startsWith('layer_control_') && window[key + '_layers']) {
                const layers = window[key + '_layers'];
                
                if (layers.base_layers) {
                    baseMaps = layers.base_layers;
                    console.log('Found base layers:', Object.keys(baseMaps));
                }
                
                if (layers.overlays) {
                    overlayMaps = layers.overlays;
                    console.log('Found overlay layers:', Object.keys(overlayMaps));
                }
                
                break;
            }
        }
        
        // Set up message listener for parent window communication
        window.addEventListener('message', function(event) {
            try {
                // Security check
                if (!event.data || !event.data.type) return;
                
                console.log('Map received message:', event.data);
                
                // Process different message types
                switch(event.data.type) {
                    case 'setBaseMap':
                        setBaseMap(event.data.value);
                        break;
                    case 'toggleLayer':
                        toggleLayer(event.data.layer, event.data.visible);
                        break;
                    case 'checkReady':
                        // Respond that we're ready
                        window.parent.postMessage({ type: 'mapReady', success: true }, '*');
                        break;
                    default:
                        console.log('Unknown message type:', event.data.type);
                }
            } catch (err) {
                console.error('Error processing message:', err);
            }
        });
        
        // Let parent know we're ready
        setTimeout(function() {
            window.parent.postMessage({ type: 'mapReady', success: true }, '*');
        }, 1000);
        
        // Function to change the base map
        function setBaseMap(mapType) {
            try {
                if (!leafletMap) {
                    console.error('Cannot set base map: map not found');
                    return;
                }
                
                console.log('Setting base map to:', mapType);
                
                // Map type names to expected label text
                const mapTypeToLabel = {
                    'light': 'Light Map',
                    'dark': 'Dark Map',
                    'street': 'Street Map'
                };
                
                const targetLabel = mapTypeToLabel[mapType] || 'Light Map';
                
                // Find the layer
                let targetLayer = null;
                for (const label in baseMaps) {
                    if (label === targetLabel) {
                        targetLayer = baseMaps[label];
                        break;
                    }
                }
                
                if (!targetLayer) {
                    console.warn('Base map not found:', targetLabel);
                    return;
                }
                
                // Remove all base layers and add the selected one
                for (const label in baseMaps) {
                    const layer = baseMaps[label];
                    if (leafletMap.hasLayer(layer)) {
                        leafletMap.removeLayer(layer);
                    }
                }
                
                leafletMap.addLayer(targetLayer);
                console.log('Base map set to:', targetLabel);
                
            } catch (err) {
                console.error('Error setting base map:', err);
            }
        }
        
        // Function to toggle a layer
        function toggleLayer(layerName, visible) {
            try {
                if (!leafletMap) {
                    console.error('Cannot toggle layer: map not found');
                    return;
                }
                
                console.log('Toggling layer:', layerName, visible);
                
                // Map layer names to expected labels in the overlay maps
                const layerToLabel = {
                    'stateBoundaries': 'State Boundaries',
                    'countiesByRegion': 'All Counties by Region',
                    'msaAreas': 'Metropolitan Statistical Areas'
                };
                
                const targetLabel = layerToLabel[layerName];
                
                if (!targetLabel) {
                    console.error('Unknown layer name:', layerName);
                    return;
                }
                
                // Find the layer
                let targetLayer = null;
                for (const label in overlayMaps) {
                    if (label === targetLabel) {
                        targetLayer = overlayMaps[label];
                        break;
                    }
                }
                
                if (!targetLayer) {
                    console.warn('Layer not found:', targetLabel);
                    return;
                }
                
                // Add or remove the layer
                if (visible) {
                    if (!leafletMap.hasLayer(targetLayer)) {
                        leafletMap.addLayer(targetLayer);
                    }
                } else {
                    if (leafletMap.hasLayer(targetLayer)) {
                        leafletMap.removeLayer(targetLayer);
                    }
                }
                
                console.log('Layer', targetLabel, 'is now', visible ? 'visible' : 'hidden');
                
            } catch (err) {
                console.error('Error toggling layer:', err);
            }
        }
    });
    </script>
    """
    m.get_root().html.add_child(folium.Element(iframe_communication_js))
    
    # Create a Figure object to hold the map
    fig = Figure(width='100%', height='100%')
    fig.add_child(m)
    
    return m, fig

def main():
    """Main function to generate the US regions map"""
    try:
        print("Getting county data...")
    county_data = get_county_data()
        
        print("Getting states data...")
        states_data = get_states_data()
    
        print("Getting MSA data...")
    msa_data = get_msa_data()
    
        print("Getting MSA-county relationships...")
    county_to_msa, _ = get_county_msa_relationships()
    
        print("Defining regions...")
    regions, ca_regions, special_county_regions, exclude_counties = define_regions()
    
        print("Assigning counties to regions and MSAs...")
    county_data = assign_counties_to_regions_and_msas(county_data, regions, ca_regions, special_county_regions, exclude_counties, county_to_msa)
    
        print("Creating interactive map...")
    m, fig = create_enhanced_interactive_map(county_data, msa_data, regions)
    
        print("Saving map to HTML...")
    m.save("us_20regions_map.html")
        
        # Inject interaction script into the map
        try:
            from map_injector import inject_script_into_map
            print("Injecting interaction script into map...")
            inject_script_into_map("us_20regions_map.html")
            print("Script injection complete")
        except Exception as e:
            print(f"Warning: Failed to inject interaction script into map: {e}")
        
        print("Map saved to us_20regions_map.html")
    
    return m, county_data, msa_data, regions
    except Exception as e:
        print(f"Error generating map: {e}")
        import traceback
        traceback.print_exc()
        return None

if __name__ == "__main__":
    main()
